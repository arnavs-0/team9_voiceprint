{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "\n",
    "\n",
    "import os\n",
    "import csv\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import commons\n",
    "import utils\n",
    "from data_utils import TextAudioLoader, TextAudioCollate, TextAudioSpeakerLoader, TextAudioSpeakerCollate\n",
    "from models import SynthesizerTrn\n",
    "from text.symbols import symbols\n",
    "from text import text_to_sequence\n",
    "\n",
    "from scipy.io.wavfile import write\n",
    "\n",
    "import random\n",
    "\n",
    "from phonemizer.backend.espeak.wrapper import EspeakWrapper\n",
    "_ESPEAK_LIBRARY = '/opt/homebrew/Cellar/espeak/1.48.04_1/lib/libespeak.1.1.48.dylib'\n",
    "EspeakWrapper.set_library(_ESPEAK_LIBRARY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text(text, hps):\n",
    "    text_norm = text_to_sequence(text, hps.data.text_cleaners)\n",
    "    if hps.data.add_blank:\n",
    "        text_norm = commons.intersperse(text_norm, 0)\n",
    "    text_norm = torch.LongTensor(text_norm)\n",
    "    return text_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hps = utils.get_hparams_from_file(\"./configs/ljs_base.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_g = SynthesizerTrn(\n",
    "    len(symbols),\n",
    "    hps.data.filter_length // 2 + 1,\n",
    "    hps.train.segment_size // hps.data.hop_length,\n",
    "    **hps.model)\n",
    "_ = net_g.eval()\n",
    "\n",
    "_ = utils.load_checkpoint(\"pretrained_ljs.pth\", net_g, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hps_ms = utils.get_hparams_from_file(\"./configs/vctk_base.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_g_ms = SynthesizerTrn(\n",
    "    len(symbols),\n",
    "    hps_ms.data.filter_length // 2 + 1,\n",
    "    hps_ms.train.segment_size // hps.data.hop_length,\n",
    "    n_speakers=hps_ms.data.n_speakers,\n",
    "    **hps_ms.model)\n",
    "_ = net_g.eval()\n",
    "\n",
    "_ = utils.load_checkpoint(\"pretrained_vctk.pth\", net_g_ms, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_speech(text, speaker_id, output_path):\n",
    "    text_input = get_text(text, hps_ms)  # Convert text to phonemes\n",
    "    with torch.no_grad():\n",
    "        x_tst = text_input.unsqueeze(0)\n",
    "        x_tst_lengths = torch.LongTensor([text_input.size(0)])\n",
    "        audio = net_g_ms.infer(x_tst, x_tst_lengths, sid=torch.LongTensor([speaker_id]), noise_scale=.667, noise_scale_w=0.8, length_scale=1)[0][0,0].data.float().numpy()\n",
    "        write(output_path, hps_ms.data.sampling_rate, audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"dataset/positive\", exist_ok=True)\n",
    "os.makedirs(\"dataset/negative_wrong_speaker\", exist_ok=True)\n",
    "os.makedirs(\"dataset/negative_wrong_text\", exist_ok=True)\n",
    "os.makedirs(\"dataset/negative_random\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target speaker\n",
    "for i in range(100):\n",
    "    generate_speech(\"Alexa,\", 0, f\"dataset/positive/wake_{i}.wav\")\n",
    "    print(f\"Generated positive wake word {i}\", end=\"\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other speakers\n",
    "num_speakers = net_g_ms.n_speakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(300):\n",
    "    speaker = random.choice(range(1, num_speakers))\n",
    "    generate_speech(\"Alexa,\", speaker, f\"dataset/negative_wrong_speaker/wake_{i}.wav\")\n",
    "    print(f\"Generated negative wake word {i}\", end=\"\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_wake_words = [\n",
    "    \"Hello,\",\n",
    "    \"Goodbye,\",\n",
    "    \"How are you?\",\n",
    "    \"What is your name?\",\n",
    "    \"Tell me a joke.\",\n",
    "    \"Play some music.\",\n",
    "    \"Set a timer for 10 minutes.\",\n",
    "    \"Turn on the lights.\",\n",
    "    \"What is the weather like?\",\n",
    "    \"Remind me to call mom.\",\n",
    "    \"Add milk to the shopping list.\",\n",
    "    \"Play my favorite song.\",\n",
    "    \"Set an alarm for 7 AM.\",\n",
    "    \"Tell me the news.\",\n",
    "    \"Find a recipe for pasta.\",\n",
    "    \"Translate 'hello' to Spanish.\",\n",
    "    \"What is the capital of France?\",\n",
    "]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(300):\n",
    "    text = random.choice(non_wake_words)\n",
    "    generate_speech(text, 0, f\"dataset/negative_wrong_text/wake_{i}.wav\")\n",
    "    print(f\"Generated negative wake word {i}\", end=\"\\r\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(500):\n",
    "    text = random.choice(non_wake_words)\n",
    "    speaker = random.choice(range(1, num_speakers))\n",
    "    generate_speech(text, speaker, f\"dataset/negative_random/wake_{i}.wav\")\n",
    "    print(f\"Generated negative wake word {i}\", end=\"\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {\n",
    "    \"positive\": 1,\n",
    "    \"negative_wrong_speaker\": 0,\n",
    "    \"negative_wrong_text\": 0,\n",
    "    \"negative_random\": 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_entries = []\n",
    "dataset_root = \"./dataset\"\n",
    "csv_path = \"./dataset.csv\"\n",
    "\n",
    "for folder_name, label in label_map.items():\n",
    "    folder_path = os.path.join(dataset_root, folder_name)\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.endswith(\".wav\"):\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            data_entries.append((file_path, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(csv_path, mode='w', newline='') as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    writer.writerow([\"path\", \"label\"])\n",
    "    for entry in data_entries:\n",
    "        writer.writerow(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"âœ… CSV saved to: {csv_path}\")\n",
    "print(f\"Total samples: {len(data_entries)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wake",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
